{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5adae90bcaed7a0bf4725a7c82fa216e8099f7bd"
   },
   "source": [
    "# **PUBG : Predict player placement tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25b5c0086ed0b380daec0b2b378f21d7f09b0ae7"
   },
   "source": [
    "### Hi kagglers 👋👋👋\n",
    "\n",
    "### Welcome on this tutorial ! It is aimed for beginners but whatever your level you could read it, and if you find a way to improve it I encourage you to fork this notebook and contribute by adding a better solution !¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a237a465f9faee904b1402fc7966a4daafcf612e"
   },
   "source": [
    "![](https://static.gamespot.com/uploads/original/1197/11970954/3206264-pubg+artwork_.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "310bacaf42e50ec9c6e7d78e7a01bc04d8751198"
   },
   "source": [
    "### In this notebook, we are going to predict the final placement of a player of the famous battle royale game PUBG. By doing this, we will go through several topics and fundamental techniques of machine learning. Here is a list of these techniques and some additional resources that you can consult to find out more:¶\n",
    "  \n",
    "\n",
    "[EDA | Data exploration](https://medium.com/python-pandemonium/introduction-to-exploratory-data-analysis-in-python-8b6bcb55c190)  \n",
    "[Features engineering](https://adataanalyst.com/machine-learning/comprehensive-guide-feature-engineering/)  \n",
    "[Evaluating a model over one training | metrics](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/)  \n",
    "[Evaluating a model over several trainings | k-fold cross validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e4730db41c12a046bd02b8330f2e3147b00d38f5"
   },
   "source": [
    "## **Table of content**\n",
    "\n",
    "1. [Data exploration](#data_exploration)\n",
    "2. [Feature egineering](#fe)\n",
    "3. [Try several models](#trymodels)\n",
    "4. [Choosing the best model](#choose)\n",
    "6. [Make prediction](#submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "36ce2f5c196e4773aff267a85a1a908b92c6168f"
   },
   "source": [
    "## **Imports & useful functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import pydot\n",
    "import re\n",
    "import dask.dataframe as dd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import sklearn\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ab970a55179ed0c9548eb1a3ed1cebfb7c606ad"
   },
   "outputs": [],
   "source": [
    "# Create table for missing data analysis\n",
    "def draw_missing_data_table(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#path of datasets\n",
    "path_train = '../input/train_V2.csv'\n",
    "path_test = '../input/test_V2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "789084c52a3741a4bdab8c1feff3bbf81be5fc8d"
   },
   "source": [
    "## **1. Data exploration** <a name=\"data_exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87e46869bf36e52e65b540541789129ee6aed3d8"
   },
   "outputs": [],
   "source": [
    "#create dataframe for training dataset and print ten first rows as preview\n",
    "train_df_raw = pd.read_csv(path_train)\n",
    "train_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "996505836b43d054f175c48e2229993930d6de3d"
   },
   "outputs": [],
   "source": [
    "# Compute some basical statistics on the dataset\n",
    "train_df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a8283d05c2f4f78fa447c5e3e1e33e517cd7b7b"
   },
   "source": [
    "### On a first look, we can suppose that there are no missing data ... let's verified it in the next cell !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f25882c9e8e8ae3eb39f5a0f46725ad4ba2e5892"
   },
   "outputs": [],
   "source": [
    "draw_missing_data_table(train_df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5c4630e0e77ff2fdb6377748f4b3a1e615e4e65"
   },
   "source": [
    "### Only one missing data ! We will delete this row during features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c13cbe0c6a8fb80f419a3fb1b8705b9ab56013e"
   },
   "outputs": [],
   "source": [
    "train_df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0046599620e16373cb77af2d13b3c0ae629638a3"
   },
   "source": [
    "### With those data we can see that one feature will need to be modified : the matchType feature. Indeed, any other features are already numerical and the Id related features are not taken into account for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "191dd9ee84b0dcdd283b71bfc53e84f8d49f60da",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's plot some histograms on main features to have a previzualisation of some of the data ...\n",
    "train_df_raw.drop(['Id', 'groupId', 'matchId', 'winPoints', 'rankPoints', 'teamKills', 'vehicleDestroys', 'roadKills', 'swimDistance', 'numGroups'], 1).hist(bins=50, figsize=(50,80), layout=(8, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd02253b6e58a4c5688939e4086ff66235510435"
   },
   "source": [
    "### Now, let's try to find some correlation in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5594c4cc38f62893ce41442d23866cb6246d768"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))  \n",
    "sns.heatmap(train_df_raw.corr(), annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "840c201359244d09dbcd378dafd8ebf0a42427c5"
   },
   "source": [
    "### With this first simple data exploration, we can observe that :\n",
    "\n",
    "* Majority of players have no kills at the end of the game (same conclusion for assists)\n",
    "* Players who killed other players have between 1 and 10 kills (maximum in almost all cases, same conclusion for assists)\n",
    "* Walk distance do not exeed 7000-8000 meters.\n",
    "* We can identify low importance variables which are almost always zero: swim distance, vehicle destroyed, roadkills\n",
    "* Teamkills are extremely rare but we can assume that when a player killed a teamate, it compromised a lot his placement so this variable can be relevant\n",
    "* The killplace variable seem to show a strong correlation between placement and number of enemy players killed for the 0 to 90 placements and a decorrelation for the end of the placements (top 10 players).\n",
    "* The final classement if well distributed between 0 and 100, with a majority of 0 probably consequence of early leaving of players.\n",
    "* winPoints and killpoints seems to be redundant, indeed, players who are doing the biggest number of kills often win their games. We may delete one of those columns.\n",
    "* obviously, damage dealt is strongly correlated withs number of kills, but not enought to delete one of those columns\n",
    "* No other strong correlation can be spotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c86c5e54aeeb83b785747f2cdd7d276a694b691c"
   },
   "source": [
    "## **2. Features engineering** <a name=\"fe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9b4f7e78387d548d690a773e10d064717907128"
   },
   "source": [
    "### **2.1 Non numerical variables treatment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58fd222c7ab594ba3e3d34316be52f4cdf1ce3a6"
   },
   "source": [
    "#### Let's take a look on the only non numerical variable of this dataset, the matchType column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03006a2bae1c392d016d1788eb46ba7948c6a04e"
   },
   "outputs": [],
   "source": [
    "train_df_raw.matchType.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a30feda162f878bd9435ec65f8422dec8554ebc"
   },
   "source": [
    "### **Thoses data need to be explained, so after a few researchs it turns out that:**\n",
    "\n",
    "- fpp means \"first person player\", those games are not very different than TPP games (third person player) so we won't treat those data differently.\n",
    "\n",
    "- crash event is described by developpers as following: “In Crash Carnage, no firearms spawn so you’ll need to focus on melee weapons, throwables, and of course your driving skills to carry your duo to that final circle. Circles move considerably faster in this event, so loot quick, grab a vehicle, and crash your way to road warrior glory.” This mode is not standard so let's check whereas lots of data cmes from this game mode.\n",
    "\n",
    "- flare event is a mode with a flare gun that allow to get some weapons and armor by calling a care package. This mode can be played with a 4 person team and it is not very different from basic squad mode so we will include flare games into squad games during feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d8c4c69a4796b5d1178ab67b569dd3c9d776c6a"
   },
   "outputs": [],
   "source": [
    "train_df_raw['matchType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a94f5631e5818f12ef0a820f4ff5b4e9d9c072df"
   },
   "source": [
    "### Interresting ... Crash games are a minority : 0.1% of total games and about 0.5% of total duo games. With this observations, we can conclude that adding crash games to duo games will not skew the result of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8731ffbc9278d6868482cfbb089a9e7f4448b05"
   },
   "source": [
    "### **2.2 Formatting function - features creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af86c204d54212e28189efe1ae989105fe7bc43f"
   },
   "source": [
    "### We now have enough informations do transform our data to make it ready for the machine learning algorithm. To do that, we will build a function that take a dataframe as argument and return a new fully formatted dataframe ready for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a9d0e4b8347017bdafe9e4d59b75af197f988d8"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df, with_categorical=False):\n",
    "\n",
    "    processed_df = df.drop(['Id', 'rankPoints'],  axis=1)\n",
    "            \n",
    "    # handle matchType column by creating dummies cols or creating new categorical variable column\n",
    "    print('-'*5 + ' handling matchType column ' + '-'*5)\n",
    "    new_matchType_cols = list()\n",
    "    if with_categorical:\n",
    "        for mtype in processed_df['matchType']:\n",
    "            if mtype in ['squad', 'squad-fpp', 'normal-squad-fpp', 'normal-squad', 'flarefpp', 'flaretpp']:\n",
    "                new_matchType_cols.append([3])\n",
    "            elif mtype in ['solo', 'solo-fpp', 'normal-solo-fpp', 'normal-solo']:\n",
    "                new_matchType_cols.append([1])\n",
    "            else:\n",
    "                new_matchType_cols.append([2])\n",
    "        match_df = pd.DataFrame(new_matchType_cols, columns=['matchType'], index=processed_df.index)\n",
    "        \n",
    "    else:\n",
    "        for mtype in processed_df['matchType']:\n",
    "            if mtype in ['squad', 'squad-fpp', 'normal-squad-fpp', 'normal-squad', 'flarefpp', 'flaretpp']:\n",
    "                new_matchType_cols.append([1, 0, 0])\n",
    "            elif mtype in ['solo', 'solo-fpp', 'normal-solo-fpp', 'normal-solo']:\n",
    "                new_matchType_cols.append([0, 0, 1])\n",
    "            else:\n",
    "                new_matchType_cols.append([0, 1, 0])\n",
    "        match_df = pd.DataFrame(new_matchType_cols, columns=['squad','duo', 'solo'], index=processed_df.index)\n",
    "        \n",
    "    processed_df = processed_df.drop(['matchType'],  axis=1)\n",
    "    \n",
    "    # create matchSize column\n",
    "    print('-'*5 + ' create matchSize column ' + '-'*5)\n",
    "    match_size = processed_df.groupby(['matchId']).size().reset_index(name='matchSize')\n",
    "    processed_df = processed_df.merge(match_size, how='left', on=['matchId'])\n",
    "    \n",
    "    # create teamSize column\n",
    "    print('-'*5 + ' create teamSize column ' + '-'*5)\n",
    "    processed_df['combinedId'] = processed_df['matchId'] + processed_df['groupId']\n",
    "    group_size = processed_df.groupby(['combinedId']).size().reset_index(name='teamSize')\n",
    "    processed_df = processed_df.merge(group_size, how='left', on=['combinedId'])\n",
    "    \n",
    "    # create totalDistance col\n",
    "    print('-'*5 + ' create totalDistance column ' + '-'*5)\n",
    "    processed_df['totalDistance'] = processed_df['rideDistance'] + processed_df['walkDistance'] + processed_df['swimDistance']\n",
    "    #processed_df['headshotRate'] = processed_df['headshotKills'] / processed_df['kills']\n",
    "    #processed_df['killstreaksRate'] = processed_df['killStreaks'] / processed_df['kills']\n",
    "    \n",
    "    processed_df = processed_df.drop(['combinedId', 'matchId', 'groupId'],  axis=1)\n",
    "    processed_df = processed_df.join(match_df)\n",
    "    \n",
    "    # delete low importances features\n",
    "    processed_df = processed_df.drop(['teamKills', 'vehicleDestroys', 'roadKills', 'swimDistance', 'headshotKills', 'solo', 'duo', 'squad'], 1)\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06c3acf429d8d09968c07e8c1c06f88875bb62db"
   },
   "source": [
    "## **3. Make prediction**  <a name=\"submission\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76dcfa68a4ce91afdbe5b39027cf86c2df6bc0a8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = preprocess_data(train_df_raw.dropna())\n",
    "X_train = train_df.drop('winPlacePerc', 1)\n",
    "y_train = train_df['winPlacePerc']\n",
    "sc = StandardScaler()\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train.values), index=X_train.index, columns=X_train.columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2825aa11e1991e51ce52c52f6b822311c4180e4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df_raw = pd.read_csv(path_test)\n",
    "# assert there are no missing data as in the train dataframe\n",
    "draw_missing_data_table(test_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b359e0a6844081519eea821118ae9c260a25928",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the same transformation on test dataset than on train dataset\n",
    "X_test = preprocess_data(test_df_raw)\n",
    "X_test = pd.DataFrame(sc.fit_transform(X_test.values), index=X_test.index, columns=X_test.columns)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46b420d0f7caaf8f451d0148f1eea1d17dd18611",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create and train model on train data sample\n",
    "params = {\n",
    "    #'num_leaves': 2048,\n",
    "    'learning_rate': 0.001,\n",
    "    #'n_estimators': 1000,\n",
    "    #'max_depth':10,\n",
    "    'min_data_in_leaf': 400,\n",
    "    'max_bin': 10000,\n",
    "    #'bagging_fraction':0.8,\n",
    "    #'bagging_freq':5,\n",
    "    #'feature_fraction':0.9,\n",
    "    #'verbose':50,\n",
    "    'boosting_type': 'dart',\n",
    "    'random_state': 42,\n",
    "    'objective' : 'regression',\n",
    "    'metric': 'mae'\n",
    "    }\n",
    "\n",
    "model = lgb.LGBMRegressor(**params, verbose=2, silent=False)\n",
    "model.fit(X_train, y_train, eval_metric= 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66f225353ff648db8e31fbef53943baa8760d0cf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict for test data sample\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5bda6353a150e8b1dd527b78b11c7b59ad7217b"
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2034750578e55bf56fa7f2bdf18dc3358404238"
   },
   "outputs": [],
   "source": [
    "# Tip found here: https://www.kaggle.com/anycode/simple-nn-baseline-3\n",
    "for i in range(len(test_df_raw)):\n",
    "    winPlacePerc = prediction[i]\n",
    "    maxPlace = int(test_df_raw.iloc[i]['maxPlace'])\n",
    "    if maxPlace == 0:\n",
    "        winPlacePerc = 0.0\n",
    "    elif maxPlace == 1:\n",
    "        winPlacePerc = 1.0\n",
    "    else:\n",
    "        gap = 1.0 / (maxPlace - 1)\n",
    "        winPlacePerc = round(winPlacePerc / gap) * gap\n",
    "    \n",
    "    if winPlacePerc < 0: winPlacePerc = 0.0\n",
    "    if winPlacePerc > 1: winPlacePerc = 1.0    \n",
    "    prediction[i] = winPlacePerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60a242dce4dcb834e257cabf646d8f33d6f35df3"
   },
   "outputs": [],
   "source": [
    "result_df = test_df_raw.copy()\n",
    "result_df['winPlacePerc'] = prediction\n",
    "\n",
    "result_df.head()\n",
    "result_df.to_csv('submission.csv', columns=['Id', 'winPlacePerc'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
