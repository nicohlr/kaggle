{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Hub - Bounding boxes coordinates corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### This kernel is highly inspired by [**this code**](https://www.kaggle.com/xhlulu/intro-to-tf-hub-for-object-detection), please do not hesitate to upvote this kernel and the original one if it helps you.\n",
    "### According to [**this discussion**](https://www.kaggle.com/c/open-images-2019-object-detection/discussion/98205), it seems that the order of coordinates for bounding boxes is different between kaggle and tensorflow. Putting the coordinates back in the correct order may give a much higher score using TF Hub as it is shown in the [**original kernel**](https://www.kaggle.com/xhlulu/intro-to-tf-hub-for-object-detection). In this kernel, we will implement this small correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction string into kaggle format, making correction for BB coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction_string(image_id, result):\n",
    "    prediction_strings = []\n",
    "\n",
    "    for i in range(len(result['detection_scores'])):\n",
    "        class_name = result['detection_class_names'][i].decode(\"utf-8\")\n",
    "        # Coordinates of the bounding box in the correct order\n",
    "        corrected_coordinates = [result['detection_boxes'][i][1], result['detection_boxes'][i][0], result['detection_boxes'][i][3], result['detection_boxes'][i][2]]\n",
    "        boxes = corrected_coordinates\n",
    "        score = result['detection_scores'][i]\n",
    "\n",
    "        prediction_strings.append(\n",
    "            f\"{class_name} {score} \" + \" \".join(map(str, boxes))\n",
    "        )\n",
    "\n",
    "    prediction_string = \" \".join(prediction_strings)\n",
    "\n",
    "    return {\n",
    "        \"ImageID\": image_id,\n",
    "        \"PredictionString\": prediction_string\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 7488/99999 [24:59<5:08:07,  5.00it/s]"
     ]
    }
   ],
   "source": [
    "sample_submission_df = pd.read_csv('../input/sample_submission.csv')\n",
    "image_ids = sample_submission_df['ImageId']\n",
    "predictions = []\n",
    "\n",
    "# Create session\n",
    "with tf.Graph().as_default():\n",
    "    # Create our inference graph\n",
    "    image_string_placeholder = tf.placeholder(tf.string)\n",
    "    decoded_image = tf.image.decode_jpeg(image_string_placeholder)\n",
    "    decoded_image_float = tf.image.convert_image_dtype(image=decoded_image, dtype=tf.float32)\n",
    "    # Expanding image from (height, width, 3) to (1, height, width, 3)\n",
    "    image_tensor = tf.expand_dims(decoded_image_float, 0)\n",
    "    # Load the model from tfhub.dev, and create a detector_output tensor\n",
    "    model_url = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
    "    detector = hub.Module(model_url)\n",
    "    detector_output = detector(image_tensor, as_dict=True)\n",
    "    # Initialize the Session\n",
    "    init_ops = [tf.global_variables_initializer(), tf.tables_initializer()]\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_ops)\n",
    "\n",
    "# Make prediction on test set\n",
    "for image_id in tqdm(image_ids):\n",
    "    # Load the image string\n",
    "    image_path = f'../input/test/{image_id}.jpg'\n",
    "    with tf.gfile.Open(image_path, \"rb\") as binfile:\n",
    "        image_string = binfile.read()\n",
    "\n",
    "    # Run our session\n",
    "    result_out = sess.run(\n",
    "        detector_output,\n",
    "        feed_dict={image_string_placeholder: image_string}\n",
    "    )\n",
    "    predictions.append(format_prediction_string(image_id, result_out))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
