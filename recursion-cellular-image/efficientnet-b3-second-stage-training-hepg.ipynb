{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append('../input/efficientnet/efficientnet-pytorch/EfficientNet-PyTorch/')\n",
    "sys.path.append('../input/radampytorch/radam/RAdam/')\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "from radam import RAdam\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/recursion-cellular-image-classification/train.csv')\n",
    "test_df = pd.read_csv('../input/recursion-cellular-image-classification/test.csv')\n",
    "sub = pd.read_csv('../input/recursion-cellular-image-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_hepg = train_df.drop(train_df[train_df.experiment.str.find('HEPG') == -1].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radampytorch',\n",
       " 'recursion-cellular-image-classification',\n",
       " 'efficientnet',\n",
       " 'fork-of-fork-of-fork-of-efficientnet-b3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, site=1, transforms=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.site = site\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        exp, well, plate = self.df.loc[idx,['experiment', 'well', 'plate']].values\n",
    "        img_channels = [np.array(Image.open(os.path.join(self.img_dir,\n",
    "                                             exp,\n",
    "                                             f'Plate{plate}',\n",
    "                                             f'{well}_s{self.site}_w{channel}.png')), \n",
    "                                          dtype=np.float32) for channel in range(1,7)]\n",
    "        \n",
    "        one_img = np.stack([channel for channel in img_channels],axis=2)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            one_img = self.transforms(one_img)\n",
    "        if self.img_dir == '../input/recursion-cellular-image-classification/train/':\n",
    "            return one_img, self.df.loc[idx,['sirna']].astype('int32').values\n",
    "        else:\n",
    "            return one_img     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations for data\n",
    "aug = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.485, 0.456, 0.456, 0.406, 0.406],\n",
    "                                 std=[0.229, 0.229, 0.225, 0.225, 0.224, 0.224])\n",
    "])\n",
    "\n",
    "# Dataset & data loaders\n",
    "dataset1 = CellDataset(df=train_df_hepg, img_dir='../input/recursion-cellular-image-classification/train/', transforms=aug)\n",
    "dataset2 = CellDataset(df=train_df_hepg, img_dir='../input/recursion-cellular-image-classification/train/', transforms=aug, site=2)\n",
    "dataset = ConcatDataset([dataset1, dataset2])\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=12, shuffle=True)\n",
    "\n",
    "test_dataset = CellDataset(df=test_df, img_dir='../input/recursion-cellular-image-classification/test/', transforms=aug)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth\" to /tmp/.cache/torch/checkpoints/efficientnet-b3-5fb5a3c3.pth\n",
      "100%|██████████| 47.1M/47.1M [00:00<00:00, 94.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=1108)\n",
    "\n",
    "# Changes count input channels of our model\n",
    "trained_kernel = model._conv_stem.weight\n",
    "new_conv = nn.Sequential(nn.Conv2d(6, 40, kernel_size=(3,3), stride=(2,2), bias=False),\n",
    "            nn.ZeroPad2d(padding=(0, 1, 0, 1)))\n",
    "with torch.no_grad():\n",
    "    new_conv[0].weight[:,:] = torch.stack([torch.mean(trained_kernel, 1)]*6, dim=1)\n",
    "model._conv_stem = new_conv\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = RAdam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../input/fork-of-fork-of-fork-of-efficientnet-b3/model.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch_num = checkpoint['epoch']\n",
    "\n",
    "num_epochs = 6 + epoch_num  # add epochs previously done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 -> Train Loss: 1.4478\n",
      "Epoch 22 -> Train Loss: 0.0574\n",
      "Epoch 23 -> Train Loss: 0.5576\n",
      "Epoch 24 -> Train Loss: 0.6003\n",
      "Epoch 25 -> Train Loss: 0.4666\n",
      "Epoch 26 -> Train Loss: 0.6480\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(epoch_num, num_epochs):\n",
    "    for batch_i, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target[:,0].long().cuda()\n",
    "        #print(data.shape)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    print('Epoch {} -> Train Loss: {:.4f}'.format(epoch+1, loss.item()))\n",
    "    \n",
    "torch.save({\n",
    "            'epoch': num_epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \n",
    "    'model.tar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
